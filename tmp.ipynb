{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reward Modeling 脚本详细解释\n",
   "id": "3e12cce0caef5e22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T06:25:25.615020Z",
     "start_time": "2024-07-09T06:25:07.241826Z"
    }
   },
   "cell_type": "code",
   "source": "from reward_modeling import *",
   "id": "fcf6f0bce6eb98",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 初始化\n",
    "- 导入必要的库和模块: 代码开始导入了多个库,包括 PyTorch、Transformers、PEFT 等。这些库提供了模型训练和数据处理所需的核心功能。\n",
    "- 定义模型类别常量 (MODEL_CLASSES): 创建了一个字典,将模型类型映射到相应的配置、模型和分词器类。这使得代码可以灵活地支持多种模型架构。\n",
    "- 定义数据类: 使用 Python 的 dataclass 装饰器定义了几个数据类(ModelArguments, DataArguments, ScriptArguments),用于存储和管理各种参数。\n",
    "- 解析命令行参数: 使用 HfArgumentParser 解析命令行参数,将它们转换为之前定义的数据类的实例。"
   ],
   "id": "ec2c9cbb7ba57ca4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 几个数据类(ModelArguments, DataArguments, ScriptArguments)\n",
    "\n",
    "\n",
    "\n",
    "1. 如何使用 dataclasses.field 为数据类字段设置默认值和元数据？请给出示例。\n",
    "2. __post_init__ 方法的作用是什么？请描述其在数据类中的用途，并给出一个验证字段值的示例。\n",
    "\n",
    "\n"
   ],
   "id": "3866e2650f5adcfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T06:46:41.436298Z",
     "start_time": "2024-07-09T06:46:41.431378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Union, List, Dict, Any\n",
    "\n",
    "# 假设这里是 ModelArguments, DataArguments, ScriptArguments 的定义\n",
    "# 由于代码已经在上文中给出，这里不再重复定义\n",
    "\n",
    "# 测试 ModelArguments\n",
    "model_args = ModelArguments(\n",
    "    model_type=\"bert\",\n",
    "    model_name_or_path=\"bert-base-uncased\",\n",
    "    tokenizer_name_or_path=\"bert-base-uncased\",\n",
    "    load_in_4bit=False,\n",
    "    load_in_8bit=False,\n",
    "    cache_dir=\"./cache\",\n",
    "    use_fast_tokenizer=True,\n",
    "    torch_dtype=\"float32\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 测试 DataArguments\n",
    "data_args = DataArguments(\n",
    "    dataset_name=\"squad\",\n",
    "    dataset_config_name=\"v2\",\n",
    "    train_file_dir=\"./data/train\",\n",
    "    validation_file_dir=\"./data/valid\",\n",
    "    max_source_length=512,\n",
    "    max_target_length=128,\n",
    "    overwrite_cache=False,\n",
    "    validation_split_percentage=5,\n",
    "    preprocessing_num_workers=4\n",
    ")\n",
    "\n",
    "# 测试 ScriptArguments\n",
    "script_args = ScriptArguments(\n",
    "    use_peft=True,\n",
    "    target_modules=\"all\",\n",
    "    lora_rank=8,\n",
    "    lora_dropout=0.05,\n",
    "    lora_alpha=32.0,\n",
    "    modules_to_save=None,\n",
    "    peft_path=None,\n",
    "    template_name=\"vicuna\"\n",
    ")\n",
    "\n",
    "# 打印实例化对象，验证参数\n",
    "print(model_args)\n",
    "print(data_args)\n",
    "print(script_args)"
   ],
   "id": "46db8180d75f7d66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArguments(model_type='bert', model_name_or_path='bert-base-uncased', tokenizer_name_or_path='bert-base-uncased', load_in_4bit=False, load_in_8bit=False, cache_dir='./cache', use_fast_tokenizer=True, torch_dtype='float32', device_map='auto', trust_remote_code=True)\n",
      "DataArguments(dataset_name='squad', dataset_config_name='v2', train_file_dir='./data/train', validation_file_dir='./data/valid', max_source_length=512, max_target_length=128, max_train_samples=None, max_eval_samples=None, overwrite_cache=False, validation_split_percentage=5, preprocessing_num_workers=4)\n",
      "ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=32.0, modules_to_save=None, peft_path=None, template_name='vicuna')\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 奖励模型的特殊数据处理器（RewardDataCollatorWithPadding）\n",
    "\n",
    "RewardDataCollatorWithPadding 类与 ModelArguments、DataArguments 和 ScriptArguments 这几个类在本质上有很大的不同。\n",
    "\n",
    "特殊性原因：\n",
    "- 奖励模型使用成对数据（选择vs拒绝的回答）\n",
    "- 需要特殊的批处理方式\n",
    "- 要求对不同长度的回答进行填充\n",
    "- 可能需要特定的输入格式（如系统提示+对话历史+当前问题）\n",
    "- 提高训练效率\n",
    "- 增加数据处理的灵活性\n",
    "\n",
    "RewardDataCollatorWithPadding 的主要功能：\n",
    "- 分别处理\"选择\"和\"拒绝\"的输入\n",
    "- 对输入进行适当的填充\n",
    "- 将处理后的数据组织成模型所需的格式\n",
    "\n",
    "与其他参数类（如ModelArguments）的区别：\n",
    "1. 用途：数据处理 vs 配置管理\n",
    "2. 定义：包含方法的完整类 vs 简单的数据容器\n",
    "3. 使用时机：训练过程中持续使用 vs 训练开始前设置\n",
    "4. 复杂度：包含数据处理逻辑 vs 主要是属性定义\n",
    "5. 可定制性：根据任务需求可调整 vs 主要由外部输入决定\n",
    "6. 生命周期：每批次调用 vs 整个训练过程中保持不变\n",
    "\n",
    "总结：RewardDataCollatorWithPadding 是动态的功能组件，而其他参数类是静态的配置容器，反映了它们在机器学习管道中的不同角色和职责。"
   ],
   "id": "abd73f0bf92c8900"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T06:25:25.625124Z",
     "start_time": "2024-07-09T06:25:25.616590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "import torch\n",
    "\n",
    "# 复制 RewardDataCollatorWithPadding 类定义（如您提供的代码）\n",
    "\n",
    "# 创建一个模拟的分词器\n",
    "class MockTokenizer:\n",
    "    def pad(self, features, padding, max_length, pad_to_multiple_of, return_tensors):\n",
    "        max_length = max(len(f['input_ids']) for f in features)\n",
    "        padded_features = []\n",
    "        for feature in features:\n",
    "            pad_length = max_length - len(feature['input_ids'])\n",
    "            padded_feature = {\n",
    "                'input_ids': feature['input_ids'] + [0] * pad_length,\n",
    "                'attention_mask': feature['attention_mask'] + [0] * pad_length\n",
    "            }\n",
    "            padded_features.append(padded_feature)\n",
    "        return {\n",
    "            'input_ids': torch.tensor([f['input_ids'] for f in padded_features]),\n",
    "            'attention_mask': torch.tensor([f['attention_mask'] for f in padded_features])\n",
    "        }\n",
    "\n",
    "# 初始化 RewardDataCollatorWithPadding 实例\n",
    "tokenizer = MockTokenizer()\n",
    "data_collator = RewardDataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 准备模拟的输入数据\n",
    "mock_features = [\n",
    "    {\n",
    "        'input_ids_chosen': [1, 2, 3],\n",
    "        'attention_mask_chosen': [1, 1, 1],\n",
    "        'input_ids_rejected': [4, 5],\n",
    "        'attention_mask_rejected': [1, 1]\n",
    "    },\n",
    "    {\n",
    "        'input_ids_chosen': [1, 2],\n",
    "        'attention_mask_chosen': [1, 1],\n",
    "        'input_ids_rejected': [4, 5, 6],\n",
    "        'attention_mask_rejected': [1, 1, 1]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 调用 RewardDataCollatorWithPadding 实例处理数据\n",
    "batch = data_collator(mock_features)\n",
    "\n",
    "# 打印并验证结果\n",
    "print(\"Processed batch:\")\n",
    "for key, value in batch.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key}:\\n{value}\\n\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\\n\")\n",
    "\n",
    "# 验证\n",
    "assert batch['input_ids_chosen'].shape == batch['attention_mask_chosen'].shape\n",
    "assert batch['input_ids_rejected'].shape == batch['attention_mask_rejected'].shape\n",
    "assert batch['return_loss'] == True\n",
    "\n",
    "print(\"All assertions passed. The RewardDataCollatorWithPadding is working as expected.\")"
   ],
   "id": "d74d1672277828bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch:\n",
      "input_ids_chosen:\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 0]])\n",
      "\n",
      "attention_mask_chosen:\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 0]])\n",
      "\n",
      "input_ids_rejected:\n",
      "tensor([[4, 5, 0],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "attention_mask_rejected:\n",
      "tensor([[1, 1, 0],\n",
      "        [1, 1, 1]])\n",
      "\n",
      "return_loss: True\n",
      "\n",
      "All assertions passed. The RewardDataCollatorWithPadding is working as expected.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "RewardDataCollatorWithPadding 在奖励模型训练中的应用\n",
    "\n",
    "偏好数据集结构：$\\mathcal{D}_{\\text{off}} = \\{(x, a^w, a^l)\\}$\n",
    "- $x$: 输入（问题/上下文）\n",
    "- $a^w$: 优选回答\n",
    "- $a^l$: 劣选回答\n",
    "\n",
    "处理流程：\n",
    "\n",
    "1. 原始数据示例\n",
    "   - $x$: \"What's the capital of France?\"\n",
    "   - $a^w$: \"The capital of France is Paris.\"\n",
    "   - $a^l$: \"The capital of France is London.\"\n",
    "\n",
    "2. 数据预处理\n",
    "   转换为 token ID：\n",
    "   - input_ids_chosen: [101, 2054, ..., 3000, 1012, 102]\n",
    "   - input_ids_rejected: [101, 2054, ..., 2414, 1012, 102]\n",
    "\n",
    "3. RewardDataCollatorWithPadding 处理\n",
    "   - 分离 \"chosen\" 和 \"rejected\" 数据\n",
    "   - 填充序列\n",
    "   - 创建注意力掩码\n",
    "   - 组织数据格式\n",
    "\n",
    "4. 输出\n",
    "   字典格式：\n",
    "   - input_ids_chosen\n",
    "   - attention_mask_chosen\n",
    "   - input_ids_rejected\n",
    "   - attention_mask_rejected\n",
    "   - return_loss: True\n",
    "\n",
    "5. 用于训练\n",
    "   - 计算优选和劣选回答得分\n",
    "   - 计算损失\n",
    "   - 反向传播和参数更新\n",
    "\n",
    "优点：\n",
    "1. 确保批次数据长度一致\n",
    "2. 保持优选和劣选回答配对\n",
    "3. 允许模型同时学习正面和负面例子\n",
    "\n",
    "结论：RewardDataCollatorWithPadding 巧妙适应奖励模型的训练需求，促进有效学习人类偏好。"
   ],
   "id": "6ef38549c4409ec2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 数据准备\n",
    "\n",
    "\n"
   ],
   "id": "d9110afd22f3faf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T07:07:23.339505Z",
     "start_time": "2024-07-09T07:07:23.302802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments, ScriptArguments))\n",
    "model_args, data_args, training_args, script_args = parser.parse_args_into_dataclasses()\n",
    "prompt_template = get_conv_template(script_args.template_name)\n",
    "\n",
    "# Preprocessing the datasets\n",
    "full_max_length = data_args.max_source_length + data_args.max_target_length\n",
    "\n",
    "def preprocess_reward_function(examples):\n",
    "    \"\"\"\n",
    "    Turn the dataset into pairs of Question + Answer, where input_ids_chosen is the preferred question + answer\n",
    "        and text_rejected is the other.\n",
    "    \"\"\"\n",
    "    new_examples = {\n",
    "        \"input_ids_chosen\": [],\n",
    "        \"attention_mask_chosen\": [],\n",
    "        \"input_ids_rejected\": [],\n",
    "        \"attention_mask_rejected\": [],\n",
    "    }\n",
    "    for system, history, question, chosen, rejected in zip(\n",
    "            examples[\"system\"],\n",
    "            examples[\"history\"],\n",
    "            examples[\"question\"],\n",
    "            examples[\"response_chosen\"],\n",
    "            examples[\"response_rejected\"]\n",
    "    ):\n",
    "        system_prompt = system or \"\"\n",
    "        chosen_messages = history + [[question, chosen]] if history else [[question, chosen]]\n",
    "        chosen_prompt = prompt_template.get_prompt(messages=chosen_messages, system_prompt=system_prompt)\n",
    "        rejected_messages = history + [[question, rejected]] if history else [[question, rejected]]\n",
    "        rejected_prompt = prompt_template.get_prompt(messages=rejected_messages, system_prompt=system_prompt)\n",
    "\n",
    "        tokenized_chosen = tokenizer(chosen_prompt)\n",
    "        tokenized_rejected = tokenizer(rejected_prompt)\n",
    "\n",
    "        new_examples[\"input_ids_chosen\"].append(tokenized_chosen[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_chosen\"].append(tokenized_chosen[\"attention_mask\"])\n",
    "        new_examples[\"input_ids_rejected\"].append(tokenized_rejected[\"input_ids\"])\n",
    "        new_examples[\"attention_mask_rejected\"].append(tokenized_rejected[\"attention_mask\"])\n",
    "    return new_examples"
   ],
   "id": "a010859e18634721",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model_type MODEL_TYPE]\n",
      "                             [--model_name_or_path MODEL_NAME_OR_PATH]\n",
      "                             [--tokenizer_name_or_path TOKENIZER_NAME_OR_PATH]\n",
      "                             [--load_in_4bit [LOAD_IN_4BIT]]\n",
      "                             [--load_in_8bit [LOAD_IN_8BIT]]\n",
      "                             [--cache_dir CACHE_DIR]\n",
      "                             [--use_fast_tokenizer [USE_FAST_TOKENIZER]]\n",
      "                             [--torch_dtype {auto,bfloat16,float16,float32}]\n",
      "                             [--device_map DEVICE_MAP]\n",
      "                             [--trust_remote_code [TRUST_REMOTE_CODE]]\n",
      "                             [--no_trust_remote_code]\n",
      "                             [--dataset_name DATASET_NAME]\n",
      "                             [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                             [--train_file_dir TRAIN_FILE_DIR]\n",
      "                             [--validation_file_dir VALIDATION_FILE_DIR]\n",
      "                             [--max_source_length MAX_SOURCE_LENGTH]\n",
      "                             [--max_target_length MAX_TARGET_LENGTH]\n",
      "                             [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                             [--max_eval_samples MAX_EVAL_SAMPLES]\n",
      "                             [--overwrite_cache [OVERWRITE_CACHE]]\n",
      "                             [--validation_split_percentage VALIDATION_SPLIT_PERCENTAGE]\n",
      "                             [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
      "                             --output_dir OUTPUT_DIR\n",
      "                             [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
      "                             [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                             [--do_predict [DO_PREDICT]]\n",
      "                             [--eval_strategy {no,steps,epoch}]\n",
      "                             [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                             [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                             [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                             [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                             [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
      "                             [--eval_delay EVAL_DELAY]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--adam_beta1 ADAM_BETA1]\n",
      "                             [--adam_beta2 ADAM_BETA2]\n",
      "                             [--adam_epsilon ADAM_EPSILON]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                             [--max_steps MAX_STEPS]\n",
      "                             [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]\n",
      "                             [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
      "                             [--warmup_ratio WARMUP_RATIO]\n",
      "                             [--warmup_steps WARMUP_STEPS]\n",
      "                             [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
      "                             [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
      "                             [--no_log_on_each_node]\n",
      "                             [--logging_dir LOGGING_DIR]\n",
      "                             [--logging_strategy {no,steps,epoch}]\n",
      "                             [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                             [--logging_steps LOGGING_STEPS]\n",
      "                             [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
      "                             [--no_logging_nan_inf_filter]\n",
      "                             [--save_strategy {no,steps,epoch}]\n",
      "                             [--save_steps SAVE_STEPS]\n",
      "                             [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                             [--save_safetensors [SAVE_SAFETENSORS]]\n",
      "                             [--no_save_safetensors]\n",
      "                             [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
      "                             [--save_only_model [SAVE_ONLY_MODEL]]\n",
      "                             [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]\n",
      "                             [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]\n",
      "                             [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
      "                             [--data_seed DATA_SEED]\n",
      "                             [--jit_mode_eval [JIT_MODE_EVAL]]\n",
      "                             [--use_ipex [USE_IPEX]] [--bf16 [BF16]]\n",
      "                             [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]\n",
      "                             [--half_precision_backend {auto,apex,cpu_amp}]\n",
      "                             [--bf16_full_eval [BF16_FULL_EVAL]]\n",
      "                             [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl}]\n",
      "                             [--tpu_num_cores TPU_NUM_CORES]\n",
      "                             [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
      "                             [--debug DEBUG [DEBUG ...]]\n",
      "                             [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
      "                             [--eval_steps EVAL_STEPS]\n",
      "                             [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                             [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]\n",
      "                             [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                             [--disable_tqdm DISABLE_TQDM]\n",
      "                             [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                             [--no_remove_unused_columns]\n",
      "                             [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                             [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
      "                             [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                             [--greater_is_better GREATER_IS_BETTER]\n",
      "                             [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                             [--fsdp FSDP]\n",
      "                             [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
      "                             [--fsdp_config FSDP_CONFIG]\n",
      "                             [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
      "                             [--accelerator_config ACCELERATOR_CONFIG]\n",
      "                             [--deepspeed DEEPSPEED]\n",
      "                             [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
      "                             [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo}]\n",
      "                             [--optim_args OPTIM_ARGS]\n",
      "                             [--adafactor [ADAFACTOR]]\n",
      "                             [--group_by_length [GROUP_BY_LENGTH]]\n",
      "                             [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                             [--report_to REPORT_TO]\n",
      "                             [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                             [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
      "                             [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
      "                             [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
      "                             [--no_dataloader_pin_memory]\n",
      "                             [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
      "                             [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
      "                             [--no_skip_memory_metrics]\n",
      "                             [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
      "                             [--push_to_hub [PUSH_TO_HUB]]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                             [--hub_model_id HUB_MODEL_ID]\n",
      "                             [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
      "                             [--hub_token HUB_TOKEN]\n",
      "                             [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
      "                             [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
      "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
      "                             [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
      "                             [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
      "                             [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]\n",
      "                             [--no_eval_do_concat_batches]\n",
      "                             [--fp16_backend {auto,apex,cpu_amp}]\n",
      "                             [--evaluation_strategy {no,steps,epoch}]\n",
      "                             [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
      "                             [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                             [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
      "                             [--mp_parameters MP_PARAMETERS]\n",
      "                             [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
      "                             [--full_determinism [FULL_DETERMINISM]]\n",
      "                             [--torchdynamo TORCHDYNAMO]\n",
      "                             [--ray_scope RAY_SCOPE]\n",
      "                             [--ddp_timeout DDP_TIMEOUT]\n",
      "                             [--torch_compile [TORCH_COMPILE]]\n",
      "                             [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
      "                             [--torch_compile_mode TORCH_COMPILE_MODE]\n",
      "                             [--dispatch_batches DISPATCH_BATCHES]\n",
      "                             [--split_batches SPLIT_BATCHES]\n",
      "                             [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
      "                             [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
      "                             [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
      "                             [--optim_target_modules OPTIM_TARGET_MODULES]\n",
      "                             [--batch_eval_metrics [BATCH_EVAL_METRICS]]\n",
      "                             [--eval_on_start [EVAL_ON_START]]\n",
      "                             [--use_peft [USE_PEFT]] [--no_use_peft]\n",
      "                             [--target_modules TARGET_MODULES]\n",
      "                             [--lora_rank LORA_RANK]\n",
      "                             [--lora_dropout LORA_DROPOUT]\n",
      "                             [--lora_alpha LORA_ALPHA]\n",
      "                             [--modules_to_save MODULES_TO_SAVE]\n",
      "                             [--peft_path PEFT_PATH]\n",
      "                             [--template_name TEMPLATE_NAME]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --output_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/finetune/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get reward dataset for tuning the reward model.\n",
    "if data_args.dataset_name is not None:\n",
    "    # Downloading and loading a dataset from the hub.\n",
    "    raw_datasets = load_dataset(\n",
    "        data_args.dataset_name,\n",
    "        data_args.dataset_config_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "    if \"validation\" not in raw_datasets.keys():\n",
    "        raw_datasets[\"validation\"] = load_dataset(\n",
    "            data_args.dataset_name,\n",
    "            data_args.dataset_config_name,\n",
    "            split=f\"train[:{data_args.validation_split_percentage}%]\",\n",
    "            cache_dir=model_args.cache_dir,\n",
    "        )\n",
    "        raw_datasets[\"train\"] = load_dataset(\n",
    "            data_args.dataset_name,\n",
    "            data_args.dataset_config_name,\n",
    "            split=f\"train[{data_args.validation_split_percentage}%:]\",\n",
    "            cache_dir=model_args.cache_dir,\n",
    "        )\n",
    "else:\n",
    "    data_files = {}\n",
    "    if data_args.train_file_dir is not None and os.path.exists(data_args.train_file_dir):\n",
    "        train_data_files = glob(f'{data_args.train_file_dir}/**/*.json', recursive=True) + glob(\n",
    "            f'{data_args.train_file_dir}/**/*.jsonl', recursive=True)\n",
    "        logger.info(f\"train files: {', '.join(train_data_files)}\")\n",
    "        data_files[\"train\"] = train_data_files\n",
    "    if data_args.validation_file_dir is not None and os.path.exists(data_args.validation_file_dir):\n",
    "        eval_data_files = glob(f'{data_args.validation_file_dir}/**/*.json', recursive=True) + glob(\n",
    "            f'{data_args.validation_file_dir}/**/*.jsonl', recursive=True)\n",
    "        logger.info(f\"eval files: {', '.join(eval_data_files)}\")\n",
    "        data_files[\"validation\"] = eval_data_files\n",
    "    raw_datasets = load_dataset(\n",
    "        'json',\n",
    "        data_files=data_files,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "    # If no validation data is there, validation_split_percentage will be used to divide the dataset.\n",
    "    if \"validation\" not in raw_datasets.keys():\n",
    "        raw_datasets[\"validation\"] = load_dataset(\n",
    "            'json',\n",
    "            data_files=data_files,\n",
    "            split=f\"train[:{data_args.validation_split_percentage}%]\",\n",
    "            cache_dir=model_args.cache_dir,\n",
    "        )\n",
    "        raw_datasets[\"train\"] = load_dataset(\n",
    "            'json',\n",
    "            data_files=data_files,\n",
    "            split=f\"train[{data_args.validation_split_percentage}%:]\",\n",
    "            cache_dir=model_args.cache_dir,\n",
    "        )\n",
    "logger.info(f\"Raw datasets: {raw_datasets}\")"
   ],
   "id": "abcebd07735e5799"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T07:07:10.912591Z",
     "start_time": "2024-07-09T07:07:10.884182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = None\n",
    "max_train_samples = 0\n",
    "if training_args.do_train:\n",
    "    if \"train\" not in raw_datasets:\n",
    "        raise ValueError(\"--do_train requires a train dataset\")\n",
    "    train_dataset = raw_datasets['train']\n",
    "    max_train_samples = len(train_dataset)\n",
    "    if data_args.max_train_samples is not None and data_args.max_train_samples > 0:\n",
    "        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "        train_dataset = train_dataset.select(range(max_train_samples))\n",
    "    logger.debug(f\"Example train_dataset[0]: {train_dataset[0]}\")\n",
    "    with training_args.main_process_first(desc=\"Train dataset tokenization\"):\n",
    "        tokenized_dataset = train_dataset.shuffle().map(\n",
    "            preprocess_reward_function,\n",
    "            batched=True,\n",
    "            num_proc=data_args.preprocessing_num_workers,\n",
    "            remove_columns=train_dataset.column_names,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "        train_dataset = tokenized_dataset.filter(\n",
    "            lambda x: 0 < len(x['input_ids_rejected']) <= full_max_length and 0 < len(\n",
    "                x['input_ids_chosen']) <= full_max_length\n",
    "        )\n",
    "        logger.debug(f\"Num train_samples: {len(train_dataset)}\")\n",
    "        logger.debug(\"Tokenized training example:\")\n",
    "        logger.debug(tokenizer.decode(train_dataset[0]['input_ids_chosen']))\n",
    "\n",
    "eval_dataset = None\n",
    "max_eval_samples = 0\n",
    "if training_args.do_eval:\n",
    "    with training_args.main_process_first(desc=\"Eval dataset tokenization\"):\n",
    "        if \"validation\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = raw_datasets[\"validation\"]\n",
    "        max_eval_samples = len(eval_dataset)\n",
    "        if data_args.max_eval_samples is not None and data_args.max_eval_samples > 0:\n",
    "            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "            eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "        logger.debug(f\"Example eval_dataset[0]: {eval_dataset[0]}\")\n",
    "        tokenized_dataset = eval_dataset.map(\n",
    "            preprocess_reward_function,\n",
    "            batched=True,\n",
    "            num_proc=data_args.preprocessing_num_workers,\n",
    "            remove_columns=eval_dataset.column_names,\n",
    "            load_from_cache_file=not data_args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "        eval_dataset = tokenized_dataset.filter(\n",
    "            lambda x: 0 < len(x['input_ids_rejected']) <= full_max_length and 0 < len(\n",
    "                x['input_ids_chosen']) <= full_max_length\n",
    "        )\n",
    "        logger.debug(f\"Num eval_samples: {len(eval_dataset)}\")\n",
    "        logger.debug(\"Tokenized eval example:\")\n",
    "        logger.debug(tokenizer.decode(eval_dataset[0]['input_ids_chosen']))"
   ],
   "id": "5ca20789cc246b6f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m      2\u001B[0m max_train_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtraining_args\u001B[49m\u001B[38;5;241m.\u001B[39mdo_train:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m raw_datasets:\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--do_train requires a train dataset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'training_args' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 模型和分词器准备\n",
    "\n",
    "- 加载预训练模型配置\n",
    "- 加载预训练模型\n",
    "- 加载分词器\n",
    "- 设置分词器参数（eos_token, bos_token, pad_token）\n",
    "\n",
    "具体到这个代码\n",
    "\n",
    "为了测试模型和分词器准备的逻辑，我们需要执行以下步骤：\n",
    "\n",
    "1. **初始化模型参数**：创建一个 `ModelArguments` 实例，包含模型类型、模型名称或路径等信息。\n",
    "2. **初始化分词器参数**：基于模型参数，创建一个分词器实例。\n",
    "3. **验证模型和分词器**：确保模型和分词器正确加载，并且分词器的特殊令牌（如 `eos_token`, `bos_token`, `pad_token`）已正确设置。"
   ],
   "id": "5fa76df228bd09e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T06:47:33.187750Z",
     "start_time": "2024-07-09T06:47:12.478305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 根据提供的参数初始化模型和分词器\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 加载模型和分词器\n",
    "# Assuming you've downloaded and extracted the model to './local_model_directory'\n",
    "model_directory = '/root/models/JimmyMa99/BaJie-Chat-mini/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory, trust_remote_code=True, device_map='cuda:0')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='cuda:0')\n",
    "\n",
    "\n",
    "tokenizer_special_tokens = {\n",
    "    'eos_token': '[EOS]',\n",
    "    'bos_token': '[BOS]',\n",
    "    'pad_token': '[PAD]'\n",
    "}\n",
    "\n",
    "\n",
    "# 设置分词器参数\n",
    "tokenizer.add_special_tokens(tokenizer_special_tokens)\n",
    "\n",
    "# 验证模型是否正确加载\n",
    "assert model is not None, \"Model is not loaded properly.\"\n",
    "\n",
    "# 验证分词器是否正确加载\n",
    "assert tokenizer is not None, \"Tokenizer is not loaded properly.\"\n",
    "\n",
    "# 验证分词器的特殊令牌是否已正确设置\n",
    "assert tokenizer.eos_token == '[EOS]', \"EOS token is not set correctly.\"\n",
    "assert tokenizer.bos_token == '[BOS]', \"BOS token is not set correctly.\"\n",
    "assert tokenizer.pad_token == '[PAD]', \"PAD token is not set correctly.\"\n",
    "\n",
    "print(\"Model and tokenizer are correctly loaded and configured.\")"
   ],
   "id": "149eee265b1c7725",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a62099af5d75409eb32c803eab823332"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer are correctly loaded and configured.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PEFT 配置\n",
    "- 如果启用 PEFT：\n",
    "  - 使用 `LoraConfig` 配置 LoRA 参数\n",
    "  - 使用 `get_peft_model` 将 LoRA 应用到模型"
   ],
   "id": "56734a4ecf3277ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PEFT 配置逻辑梳理：\n",
    "\n",
    "1. 判断是否使用 PEFT\n",
    "   - 如果 `script_args.use_peft` 为 True，进行 PEFT 配置\n",
    "   - 否则，进行全参数微调\n",
    "\n",
    "2. PEFT 配置流程\n",
    "   a. 检查是否有预训练的 PEFT 模型\n",
    "      - 如果 `script_args.peft_path` 不为 None，加载预训练的 PEFT 模型\n",
    "      - 否则，初始化新的 PEFT 模型\n",
    "\n",
    "   b. 初始化新 PEFT 模型的步骤\n",
    "      1) 如果使用 8 位量化 (`model_args.load_in_8bit` 为 True)\n",
    "         - 调用 `prepare_model_for_kbit_training` 准备模型\n",
    "      \n",
    "      2) 确定目标模块 (target_modules)\n",
    "         - 如果指定了 target_modules，进行分割\n",
    "         - 如果包含 'all'，使用 `find_all_linear_names` 函数查找所有线性层\n",
    "      \n",
    "      3) 处理需要保存的模块 (modules_to_save)\n",
    "         - 如果指定了 modules_to_save，进行分割\n",
    "      \n",
    "      4) 配置 LoRA\n",
    "         - 创建 LoraConfig 对象，设置任务类型、目标模块、LoRA 参数等\n",
    "      \n",
    "      5) 应用 PEFT\n",
    "         - 使用 `get_peft_model` 函数将 LoRA 配置应用到模型\n",
    "\n",
    "   c. 参数处理\n",
    "      - 将所有需要梯度的参数转换为 float32 类型\n",
    "      \n",
    "   d. 打印可训练参数信息\n",
    "      - 调用 `model.print_trainable_parameters()`\n",
    "\n",
    "3. 全参数微调\n",
    "   - 如果不使用 PEFT，直接打印可训练参数信息"
   ],
   "id": "28d6b266d28aafaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T06:47:38.283373Z",
     "start_time": "2024-07-09T06:47:33.188926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if script_args.use_peft:\n",
    "    logger.info(\"Fine-tuning method: LoRA(PEFT)\")\n",
    "    if script_args.peft_path is not None:\n",
    "        logger.info(f\"Peft from pre-trained model: {script_args.peft_path}\")\n",
    "        model = PeftModel.from_pretrained(model, script_args.peft_path, is_trainable=True)\n",
    "    else:\n",
    "        logger.info(\"Init new peft model\")\n",
    "        if model_args.load_in_8bit:\n",
    "            model = prepare_model_for_kbit_training(model)\n",
    "        target_modules = script_args.target_modules.split(',') if script_args.target_modules else None\n",
    "        if target_modules and 'all' in target_modules:\n",
    "            target_modules = find_all_linear_names(model, int4=False, int8=model_args.load_in_8bit)\n",
    "        modules_to_save = script_args.modules_to_save\n",
    "        if modules_to_save is not None:\n",
    "            modules_to_save = modules_to_save.split(',')\n",
    "        logger.info(f\"Peft target_modules: {target_modules}\")\n",
    "        logger.info(f\"Peft lora_rank: {script_args.lora_rank}\")\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            target_modules=target_modules,\n",
    "            inference_mode=False,\n",
    "            r=script_args.lora_rank,\n",
    "            lora_alpha=script_args.lora_alpha,\n",
    "            lora_dropout=script_args.lora_dropout,\n",
    "            modules_to_save=modules_to_save)\n",
    "        model = get_peft_model(model, peft_config)\n",
    "    for param in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        param.data = param.data.to(torch.float32)\n",
    "    model.print_trainable_parameters()\n",
    "else:\n",
    "    logger.info(\"Fine-tuning method: Full parameters training\")\n",
    "    print_trainable_parameters(model)"
   ],
   "id": "c6fec33ddb46436e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-09 14:47:33.192\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mFine-tuning method: LoRA(PEFT)\u001B[0m\n",
      "\u001B[32m2024-07-09 14:47:33.193\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m7\u001B[0m - \u001B[1mInit new peft model\u001B[0m\n",
      "\u001B[32m2024-07-09 14:47:33.193\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m16\u001B[0m - \u001B[1mPeft target_modules: ['output', 'w1', 'w2', 'w3', 'wo', 'wqkv']\u001B[0m\n",
      "\u001B[32m2024-07-09 14:47:33.194\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m17\u001B[0m - \u001B[1mPeft lora_rank: 8\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,621,056 || all params: 1,897,731,072 || trainable%: 0.45428228094059475\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 模型训练准备\n",
    "- 配置梯度检查点\n",
    "- 启用输入梯度计算\n",
    "- 设置并行训练（如果有多个 GPU）\n"
   ],
   "id": "d580d8d93e1c5c5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments, ScriptArguments))\n",
    "model_args, data_args, training_args, script_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "# Initialize our Trainer\n",
    "if training_args.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.config.use_cache = False\n",
    "else:\n",
    "    model.config.use_cache = True\n",
    "model.enable_input_require_grads()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # Keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ],
   "id": "a0fc5f39aa0fecba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 自定义训练器定义\n",
    "- 实现 `RewardTrainer` 类（继承自 `Trainer`）\n",
    "  - 重写 `compute_loss` 方法\n",
    "  - 重写 `evaluate` 方法\n",
    "  - 重写 `prediction_step` 方法\n",
    "  - 重写 `save_model` 方法"
   ],
   "id": "4fcb99728d8de27c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 训练过程\n",
    "- 初始化 `RewardTrainer`\n",
    "- 如果 `do_train` 为 True：\n",
    "  - 开始训练\n",
    "  - 记录训练指标\n",
    "  - 保存训练后的模型和分词器\n",
    "- 如果 `do_eval` 为 True：\n",
    "  - 进行评估\n",
    "  - 计算并记录评估指标"
   ],
   "id": "8cce30d93fd4ce8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=RewardDataCollatorWithPadding(\n",
    "        tokenizer=tokenizer, max_length=full_max_length, padding=\"max_length\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    logger.info(\"*** Train ***\")\n",
    "    logger.debug(f\"Train dataloader example: {next(iter(trainer.get_train_dataloader()))}\")\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    metrics[\"train_samples\"] = max_train_samples\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    model.config.use_cache = True  # enable cache after training\n",
    "    if trainer.is_world_process_zero():\n",
    "        logger.debug(f\"Training metrics: {metrics}\")\n",
    "        logger.info(f\"Saving model checkpoint to {training_args.output_dir}\")\n",
    "        save_model(model, tokenizer, training_args)\n",
    "\n",
    "# Evaluation\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    metrics[\"eval_samples\"] = max_eval_samples\n",
    "    try:\n",
    "        perplexity = math.exp(metrics[\"eval_loss\"])\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    metrics[\"perplexity\"] = perplexity\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "    if trainer.is_world_process_zero():\n",
    "        logger.debug(f\"Eval metrics: {metrics}\")"
   ],
   "id": "39152449cbd1014e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 主函数\n",
    "- 按顺序调用上述所有步骤\n"
   ],
   "id": "5cf114cabe01b950"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T13:52:25.345786Z",
     "start_time": "2024-07-09T13:52:25.336449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Sequence, Dict\n",
    "\n",
    "@dataclass\n",
    "class Conversation:\n",
    "    name: str\n",
    "    system_prompt: str\n",
    "    messages: Optional[List[Sequence[str]]]\n",
    "    roles: Optional[Sequence[str]]\n",
    "    prompt: str\n",
    "    sep: str\n",
    "    stop_str: Optional[str] = \"</s>\"\n",
    "\n",
    "    def get_prompt(self, messages: Optional[List[Sequence[str]]] = None, system_prompt: Optional[str] = \"\") -> str:\n",
    "        return \"\".join(self._format_example(messages, system_prompt))\n",
    "\n",
    "    def get_dialog(self, messages: Optional[List[Sequence[str]]] = None, system_prompt: Optional[str] = \"\") -> List[str]:\n",
    "        return self._format_example(messages, system_prompt)\n",
    "\n",
    "    def _format_example(self, messages: Optional[List[Sequence[str]]] = None, system_prompt: Optional[str] = \"\") -> List[str]:\n",
    "        system_prompt = system_prompt or self.system_prompt\n",
    "        system_prompt = system_prompt + self.sep if system_prompt else \"\"\n",
    "        messages = messages or self.messages\n",
    "        convs = []\n",
    "        for turn_idx, [user_query, bot_resp] in enumerate(messages):\n",
    "            if turn_idx == 0:\n",
    "                convs.append(system_prompt + self.prompt.format(query=user_query))\n",
    "                convs.append(bot_resp)\n",
    "            else:\n",
    "                convs.append(self.sep + self.prompt.format(query=user_query))\n",
    "                convs.append(bot_resp)\n",
    "        return convs\n",
    "\n",
    "    def append_message(self, query: str, answer: str):\n",
    "        self.messages.append([query, answer])\n",
    "\n",
    "# 全局注册表\n",
    "conv_templates: Dict[str, Conversation] = {}\n",
    "\n",
    "def register_conv_template(template: Conversation):\n",
    "    conv_templates[template.name] = template\n",
    "\n",
    "def get_conv_template(name: str) -> Conversation:\n",
    "    return conv_templates[name]\n",
    "\n",
    "# 注册一个示例模板\n",
    "register_conv_template(\n",
    "    Conversation(\n",
    "        name=\"example\",\n",
    "        system_prompt=\"This is an example system prompt.\",\n",
    "        messages=[],\n",
    "        roles=(\"USER\", \"ASSISTANT\"),\n",
    "        prompt=\"USER: {query} ASSISTANT:\",\n",
    "        sep=\"</s>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 使用已注册的模板\n",
    "example_template = get_conv_template(\"example\")\n",
    "print(example_template.get_prompt([[\"Hello\", \"Hi there!\"]]))\n"
   ],
   "id": "5414ce48a526f989",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example system prompt.</s>USER: Hello ASSISTANT:Hi there!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T13:52:28.982415Z",
     "start_time": "2024-07-09T13:52:28.978065Z"
    }
   },
   "cell_type": "code",
   "source": "2",
   "id": "45e50acabe58005a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35a13ccc773b5649"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
